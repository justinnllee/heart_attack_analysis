{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Justin Lee\n",
    "\n",
    "This notebook is prepared for the Ministry of Health and Family Welfare (MoHFW). The MoHFW aims to understand how they can use ML models to identify high-risk characteristics to heart attacks and allocate medical resources accordingly. This can be used for public awareness campaigns and public health initaitives targeting key risk factors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Business Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is based on Indian cardiovascular health statistics, medical research reports, and national surveys, incorporating data from:\n",
    "\n",
    "Indian Council of Medical Research (ICMR) – Reports on heart disease prevalence in India Ministry of Health & Family Welfare, Government of India – National health statistics World Health Organization (WHO) – India Reports – Cardiovascular disease risk factors National Family Health Survey (NFHS-5) – Demographic and health-related indicators Global Burden of Disease (GBD) Study – India-specific cardiovascular mortality rates Indian Heart Journal & AIIMS Research – Clinical insights on CVD trends in India.\n",
    "\n",
    "This dataset consists of 10,000 records with each corresponding to a patient ID and their associated health characteristics, conditions, lifestyle choices and other related metrics culminating in assessing whether or not the patient is at risk for a heart attack."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import relevant libraries\n",
    "import pandas as pd\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient_ID</th>\n",
       "      <th>State_Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Diabetes</th>\n",
       "      <th>Hypertension</th>\n",
       "      <th>Obesity</th>\n",
       "      <th>Smoking</th>\n",
       "      <th>Alcohol_Consumption</th>\n",
       "      <th>Physical_Activity</th>\n",
       "      <th>...</th>\n",
       "      <th>Diastolic_BP</th>\n",
       "      <th>Air_Pollution_Exposure</th>\n",
       "      <th>Family_History</th>\n",
       "      <th>Stress_Level</th>\n",
       "      <th>Healthcare_Access</th>\n",
       "      <th>Heart_Attack_History</th>\n",
       "      <th>Emergency_Response_Time</th>\n",
       "      <th>Annual_Income</th>\n",
       "      <th>Health_Insurance</th>\n",
       "      <th>Heart_Attack_Risk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Rajasthan</td>\n",
       "      <td>42</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>119</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>157</td>\n",
       "      <td>611025</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Himachal Pradesh</td>\n",
       "      <td>26</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>115</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>331</td>\n",
       "      <td>174527</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Assam</td>\n",
       "      <td>78</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>117</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>186</td>\n",
       "      <td>1760112</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Odisha</td>\n",
       "      <td>58</td>\n",
       "      <td>Male</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>324</td>\n",
       "      <td>1398213</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Karnataka</td>\n",
       "      <td>22</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>109</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>209</td>\n",
       "      <td>97987</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Patient_ID        State_Name  Age  Gender  Diabetes  Hypertension  Obesity  \\\n",
       "0           1         Rajasthan   42  Female         0             0        1   \n",
       "1           2  Himachal Pradesh   26    Male         0             0        0   \n",
       "2           3             Assam   78    Male         0             0        1   \n",
       "3           4            Odisha   58    Male         1             0        1   \n",
       "4           5         Karnataka   22    Male         0             0        0   \n",
       "\n",
       "   Smoking  Alcohol_Consumption  Physical_Activity  ...  Diastolic_BP  \\\n",
       "0        1                    0                  0  ...           119   \n",
       "1        0                    1                  1  ...           115   \n",
       "2        0                    0                  1  ...           117   \n",
       "3        0                    0                  1  ...            65   \n",
       "4        0                    0                  1  ...           109   \n",
       "\n",
       "   Air_Pollution_Exposure  Family_History  Stress_Level  Healthcare_Access  \\\n",
       "0                       1               0             4                  0   \n",
       "1                       0               0             7                  0   \n",
       "2                       0               1            10                  1   \n",
       "3                       0               0             1                  1   \n",
       "4                       0               0             9                  0   \n",
       "\n",
       "   Heart_Attack_History  Emergency_Response_Time  Annual_Income  \\\n",
       "0                     0                      157         611025   \n",
       "1                     0                      331         174527   \n",
       "2                     0                      186        1760112   \n",
       "3                     1                      324        1398213   \n",
       "4                     0                      209          97987   \n",
       "\n",
       "   Health_Insurance  Heart_Attack_Risk  \n",
       "0                 0                  0  \n",
       "1                 0                  0  \n",
       "2                 1                  0  \n",
       "3                 0                  0  \n",
       "4                 0                  1  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load in dataframe\n",
    "df = pd.read_csv('heart_attack_prediction_india.csv')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 26 columns):\n",
      " #   Column                   Non-Null Count  Dtype \n",
      "---  ------                   --------------  ----- \n",
      " 0   Patient_ID               10000 non-null  int64 \n",
      " 1   State_Name               10000 non-null  object\n",
      " 2   Age                      10000 non-null  int64 \n",
      " 3   Gender                   10000 non-null  object\n",
      " 4   Diabetes                 10000 non-null  int64 \n",
      " 5   Hypertension             10000 non-null  int64 \n",
      " 6   Obesity                  10000 non-null  int64 \n",
      " 7   Smoking                  10000 non-null  int64 \n",
      " 8   Alcohol_Consumption      10000 non-null  int64 \n",
      " 9   Physical_Activity        10000 non-null  int64 \n",
      " 10  Diet_Score               10000 non-null  int64 \n",
      " 11  Cholesterol_Level        10000 non-null  int64 \n",
      " 12  Triglyceride_Level       10000 non-null  int64 \n",
      " 13  LDL_Level                10000 non-null  int64 \n",
      " 14  HDL_Level                10000 non-null  int64 \n",
      " 15  Systolic_BP              10000 non-null  int64 \n",
      " 16  Diastolic_BP             10000 non-null  int64 \n",
      " 17  Air_Pollution_Exposure   10000 non-null  int64 \n",
      " 18  Family_History           10000 non-null  int64 \n",
      " 19  Stress_Level             10000 non-null  int64 \n",
      " 20  Healthcare_Access        10000 non-null  int64 \n",
      " 21  Heart_Attack_History     10000 non-null  int64 \n",
      " 22  Emergency_Response_Time  10000 non-null  int64 \n",
      " 23  Annual_Income            10000 non-null  int64 \n",
      " 24  Health_Insurance         10000 non-null  int64 \n",
      " 25  Heart_Attack_Risk        10000 non-null  int64 \n",
      "dtypes: int64(24), object(2)\n",
      "memory usage: 2.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient_ID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Diabetes</th>\n",
       "      <th>Hypertension</th>\n",
       "      <th>Obesity</th>\n",
       "      <th>Smoking</th>\n",
       "      <th>Alcohol_Consumption</th>\n",
       "      <th>Physical_Activity</th>\n",
       "      <th>Diet_Score</th>\n",
       "      <th>Cholesterol_Level</th>\n",
       "      <th>...</th>\n",
       "      <th>Diastolic_BP</th>\n",
       "      <th>Air_Pollution_Exposure</th>\n",
       "      <th>Family_History</th>\n",
       "      <th>Stress_Level</th>\n",
       "      <th>Healthcare_Access</th>\n",
       "      <th>Heart_Attack_History</th>\n",
       "      <th>Emergency_Response_Time</th>\n",
       "      <th>Annual_Income</th>\n",
       "      <th>Health_Insurance</th>\n",
       "      <th>Heart_Attack_Risk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10000.00000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.00000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>1.000000e+04</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5000.50000</td>\n",
       "      <td>49.394900</td>\n",
       "      <td>0.092900</td>\n",
       "      <td>0.24690</td>\n",
       "      <td>0.303700</td>\n",
       "      <td>0.301400</td>\n",
       "      <td>0.352800</td>\n",
       "      <td>0.595800</td>\n",
       "      <td>5.021700</td>\n",
       "      <td>224.753000</td>\n",
       "      <td>...</td>\n",
       "      <td>89.312000</td>\n",
       "      <td>0.403600</td>\n",
       "      <td>0.311300</td>\n",
       "      <td>5.518800</td>\n",
       "      <td>0.311000</td>\n",
       "      <td>0.152500</td>\n",
       "      <td>206.383400</td>\n",
       "      <td>1.022062e+06</td>\n",
       "      <td>0.344700</td>\n",
       "      <td>0.300700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2886.89568</td>\n",
       "      <td>17.280301</td>\n",
       "      <td>0.290307</td>\n",
       "      <td>0.43123</td>\n",
       "      <td>0.459878</td>\n",
       "      <td>0.458889</td>\n",
       "      <td>0.477865</td>\n",
       "      <td>0.490761</td>\n",
       "      <td>3.156394</td>\n",
       "      <td>43.359172</td>\n",
       "      <td>...</td>\n",
       "      <td>17.396486</td>\n",
       "      <td>0.490644</td>\n",
       "      <td>0.463048</td>\n",
       "      <td>2.866264</td>\n",
       "      <td>0.462926</td>\n",
       "      <td>0.359523</td>\n",
       "      <td>112.391711</td>\n",
       "      <td>5.605978e+05</td>\n",
       "      <td>0.475294</td>\n",
       "      <td>0.458585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>5.035300e+04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2500.75000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>187.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>110.000000</td>\n",
       "      <td>5.357838e+05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5000.50000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>226.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>89.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>206.000000</td>\n",
       "      <td>1.021383e+06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7500.25000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>262.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>104.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>304.000000</td>\n",
       "      <td>1.501670e+06</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>10000.00000</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>299.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>119.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>399.000000</td>\n",
       "      <td>1.999714e+06</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Patient_ID           Age      Diabetes  Hypertension       Obesity  \\\n",
       "count  10000.00000  10000.000000  10000.000000   10000.00000  10000.000000   \n",
       "mean    5000.50000     49.394900      0.092900       0.24690      0.303700   \n",
       "std     2886.89568     17.280301      0.290307       0.43123      0.459878   \n",
       "min        1.00000     20.000000      0.000000       0.00000      0.000000   \n",
       "25%     2500.75000     35.000000      0.000000       0.00000      0.000000   \n",
       "50%     5000.50000     49.000000      0.000000       0.00000      0.000000   \n",
       "75%     7500.25000     64.000000      0.000000       0.00000      1.000000   \n",
       "max    10000.00000     79.000000      1.000000       1.00000      1.000000   \n",
       "\n",
       "            Smoking  Alcohol_Consumption  Physical_Activity    Diet_Score  \\\n",
       "count  10000.000000         10000.000000       10000.000000  10000.000000   \n",
       "mean       0.301400             0.352800           0.595800      5.021700   \n",
       "std        0.458889             0.477865           0.490761      3.156394   \n",
       "min        0.000000             0.000000           0.000000      0.000000   \n",
       "25%        0.000000             0.000000           0.000000      2.000000   \n",
       "50%        0.000000             0.000000           1.000000      5.000000   \n",
       "75%        1.000000             1.000000           1.000000      8.000000   \n",
       "max        1.000000             1.000000           1.000000     10.000000   \n",
       "\n",
       "       Cholesterol_Level  ...  Diastolic_BP  Air_Pollution_Exposure  \\\n",
       "count       10000.000000  ...  10000.000000            10000.000000   \n",
       "mean          224.753000  ...     89.312000                0.403600   \n",
       "std            43.359172  ...     17.396486                0.490644   \n",
       "min           150.000000  ...     60.000000                0.000000   \n",
       "25%           187.000000  ...     74.000000                0.000000   \n",
       "50%           226.000000  ...     89.000000                0.000000   \n",
       "75%           262.000000  ...    104.000000                1.000000   \n",
       "max           299.000000  ...    119.000000                1.000000   \n",
       "\n",
       "       Family_History  Stress_Level  Healthcare_Access  Heart_Attack_History  \\\n",
       "count    10000.000000  10000.000000       10000.000000          10000.000000   \n",
       "mean         0.311300      5.518800           0.311000              0.152500   \n",
       "std          0.463048      2.866264           0.462926              0.359523   \n",
       "min          0.000000      1.000000           0.000000              0.000000   \n",
       "25%          0.000000      3.000000           0.000000              0.000000   \n",
       "50%          0.000000      6.000000           0.000000              0.000000   \n",
       "75%          1.000000      8.000000           1.000000              0.000000   \n",
       "max          1.000000     10.000000           1.000000              1.000000   \n",
       "\n",
       "       Emergency_Response_Time  Annual_Income  Health_Insurance  \\\n",
       "count             10000.000000   1.000000e+04      10000.000000   \n",
       "mean                206.383400   1.022062e+06          0.344700   \n",
       "std                 112.391711   5.605978e+05          0.475294   \n",
       "min                  10.000000   5.035300e+04          0.000000   \n",
       "25%                 110.000000   5.357838e+05          0.000000   \n",
       "50%                 206.000000   1.021383e+06          0.000000   \n",
       "75%                 304.000000   1.501670e+06          1.000000   \n",
       "max                 399.000000   1.999714e+06          1.000000   \n",
       "\n",
       "       Heart_Attack_Risk  \n",
       "count       10000.000000  \n",
       "mean            0.300700  \n",
       "std             0.458585  \n",
       "min             0.000000  \n",
       "25%             0.000000  \n",
       "50%             0.000000  \n",
       "75%             1.000000  \n",
       "max             1.000000  \n",
       "\n",
       "[8 rows x 24 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Patient_ID                 0\n",
       "State_Name                 0\n",
       "Age                        0\n",
       "Gender                     0\n",
       "Diabetes                   0\n",
       "Hypertension               0\n",
       "Obesity                    0\n",
       "Smoking                    0\n",
       "Alcohol_Consumption        0\n",
       "Physical_Activity          0\n",
       "Diet_Score                 0\n",
       "Cholesterol_Level          0\n",
       "Triglyceride_Level         0\n",
       "LDL_Level                  0\n",
       "HDL_Level                  0\n",
       "Systolic_BP                0\n",
       "Diastolic_BP               0\n",
       "Air_Pollution_Exposure     0\n",
       "Family_History             0\n",
       "Stress_Level               0\n",
       "Healthcare_Access          0\n",
       "Heart_Attack_History       0\n",
       "Emergency_Response_Time    0\n",
       "Annual_Income              0\n",
       "Health_Insurance           0\n",
       "Heart_Attack_Risk          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check how many null values there are\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    6993\n",
       "1    3007\n",
       "Name: Heart_Attack_Risk, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check class imbalance in our target column\n",
    "df['Heart_Attack_Risk'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our target variable is imbalanced (with roughly a 70/30 split). We will prepare our data to handle this class imbalance and then proceed with random under sampling on a logistic regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features (X) and the target variable (y)\n",
    "# Dropping non-informative columns\n",
    "X = df.drop(columns=[\"Heart_Attack_Risk\", \"Patient_ID\", \"State_Name\"])\n",
    "y = df[\"Heart_Attack_Risk\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    5516\n",
       "0    4484\n",
       "Name: Gender, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 'Gender' is our only categorical variable left. We'll encode 'Gender' as binary (0 = Female, 1 = Male)\n",
    "label_encoder = LabelEncoder()\n",
    "X[\"Gender\"] = label_encoder.fit_transform(X[\"Gender\"])\n",
    "\n",
    "# Verify encoding\n",
    "X[\"Gender\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    3007\n",
       "0    3007\n",
       "Name: Heart_Attack_Risk, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply Random Undersampling to balance the dataset\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "X_resampled, y_resampled = rus.fit_resample(X, y)\n",
    "\n",
    "# Check new class distribution\n",
    "pd.Series(y_resampled).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4209, 23), (1805, 23))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split into 70% training and 30% testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_resampled, y_resampled, test_size=0.3, random_state=42, stratify=y_resampled)\n",
    "\n",
    "# Check the shape of training and testing sets\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Diabetes</th>\n",
       "      <th>Hypertension</th>\n",
       "      <th>Obesity</th>\n",
       "      <th>Smoking</th>\n",
       "      <th>Alcohol_Consumption</th>\n",
       "      <th>Physical_Activity</th>\n",
       "      <th>Diet_Score</th>\n",
       "      <th>Cholesterol_Level</th>\n",
       "      <th>...</th>\n",
       "      <th>Systolic_BP</th>\n",
       "      <th>Diastolic_BP</th>\n",
       "      <th>Air_Pollution_Exposure</th>\n",
       "      <th>Family_History</th>\n",
       "      <th>Stress_Level</th>\n",
       "      <th>Healthcare_Access</th>\n",
       "      <th>Heart_Attack_History</th>\n",
       "      <th>Emergency_Response_Time</th>\n",
       "      <th>Annual_Income</th>\n",
       "      <th>Health_Insurance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1744</th>\n",
       "      <td>-0.839303</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.589428</td>\n",
       "      <td>1.415297</td>\n",
       "      <td>...</td>\n",
       "      <td>1.629470</td>\n",
       "      <td>0.547908</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.175445</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.573181</td>\n",
       "      <td>-0.870631</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>866</th>\n",
       "      <td>0.904802</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.943187</td>\n",
       "      <td>-0.331269</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.872261</td>\n",
       "      <td>0.260280</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.522951</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.262888</td>\n",
       "      <td>0.949112</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1143</th>\n",
       "      <td>-0.548619</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.626610</td>\n",
       "      <td>0.702882</td>\n",
       "      <td>...</td>\n",
       "      <td>1.013659</td>\n",
       "      <td>-0.545079</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.519566</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.315173</td>\n",
       "      <td>-0.783374</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2649</th>\n",
       "      <td>-0.257935</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.259764</td>\n",
       "      <td>0.197297</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.218655</td>\n",
       "      <td>0.030177</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.522951</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.715029</td>\n",
       "      <td>1.480959</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1040</th>\n",
       "      <td>1.137350</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.943187</td>\n",
       "      <td>0.013448</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.217962</td>\n",
       "      <td>0.030177</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.214578</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.402933</td>\n",
       "      <td>-0.556504</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Age  Gender  Diabetes  Hypertension  Obesity  Smoking  \\\n",
       "1744 -0.839303       0         0             0        0        0   \n",
       "866   0.904802       0         0             1        0        0   \n",
       "1143 -0.548619       1         0             0        0        0   \n",
       "2649 -0.257935       1         0             1        1        0   \n",
       "1040  1.137350       1         0             0        0        0   \n",
       "\n",
       "      Alcohol_Consumption  Physical_Activity  Diet_Score  Cholesterol_Level  \\\n",
       "1744                    1                  0   -1.589428           1.415297   \n",
       "866                     0                  1    0.943187          -0.331269   \n",
       "1143                    0                  1    0.626610           0.702882   \n",
       "2649                    1                  0    1.259764           0.197297   \n",
       "1040                    1                  0    0.943187           0.013448   \n",
       "\n",
       "      ...  Systolic_BP  Diastolic_BP  Air_Pollution_Exposure  Family_History  \\\n",
       "1744  ...     1.629470      0.547908                       0               1   \n",
       "866   ...    -0.872261      0.260280                       0               0   \n",
       "1143  ...     1.013659     -0.545079                       1               0   \n",
       "2649  ...    -1.218655      0.030177                       0               1   \n",
       "1040  ...    -0.217962      0.030177                       1               1   \n",
       "\n",
       "      Stress_Level  Healthcare_Access  Heart_Attack_History  \\\n",
       "1744     -0.175445                  1                     1   \n",
       "866      -0.522951                  1                     0   \n",
       "1143      0.519566                  0                     0   \n",
       "2649     -0.522951                  0                     0   \n",
       "1040      1.214578                  0                     1   \n",
       "\n",
       "      Emergency_Response_Time  Annual_Income  Health_Insurance  \n",
       "1744                -1.573181      -0.870631                 0  \n",
       "866                 -1.262888       0.949112                 1  \n",
       "1143                 0.315173      -0.783374                 0  \n",
       "2649                -1.715029       1.480959                 1  \n",
       "1040                -0.402933      -0.556504                 0  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Identify numeric columns that need scaling\n",
    "numeric_columns = [\n",
    "    \"Age\", \"Diet_Score\", \"Cholesterol_Level\", \"Triglyceride_Level\", \"LDL_Level\", \"HDL_Level\", \n",
    "    \"Systolic_BP\", \"Diastolic_BP\", \"Stress_Level\", \"Emergency_Response_Time\", \"Annual_Income\"\n",
    "]\n",
    "\n",
    "# Initialize the StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Copy the original data to keep the binary columns unchanged\n",
    "X_train_scaled = X_train.copy()\n",
    "X_test_scaled = X_test.copy()\n",
    "\n",
    "# Apply scaling only to the specified numeric columns\n",
    "X_train_scaled[numeric_columns] = scaler.fit_transform(X_train[numeric_columns])\n",
    "X_test_scaled[numeric_columns] = scaler.transform(X_test[numeric_columns])\n",
    "\n",
    "# View summary of preprocessed data\n",
    "X_train_scaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and train Logistic Regression model\n",
    "log_reg = LogisticRegression(random_state=42)\n",
    "log_reg.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make Predictions\n",
    "y_pred = log_reg.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4919667590027701\n",
      "Confusion Matrix:\n",
      " [[419 484]\n",
      " [433 469]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.46      0.48       903\n",
      "           1       0.49      0.52      0.51       902\n",
      "\n",
      "    accuracy                           0.49      1805\n",
      "   macro avg       0.49      0.49      0.49      1805\n",
      "weighted avg       0.49      0.49      0.49      1805\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print evaluation results\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy is around 49%, which is very close to random chance (50%) in a binary classification problem. This suggests that the model is not effectively distinguishing between high-risk and low-risk individuals.\n",
    "\n",
    "We have 469 correctly predicted high-risk cases, 419 correctly predicted low-risk cases, 484 wrongly predicted high-risk cases that were actually low-risk, and 433 wrongly predicted low-risk cases that were actually high-risk.\n",
    "\n",
    "We had a precision of 0.49, meaning a high false positive rate (misclassifying low-risk as high-risk). This is bad if governments use this model for public health initiatives as they may over-allocate resources to false high-risk cases. We had a recall of 0.52, meaning this model only captures 52% of actual heart attack risk cases and missing the other 48%. This model obtained an F1-score of ~0.49 which is below for both classes, which leans on the poorer side of balance between precision and recall."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Justin's Draft Notes\n",
    "- started with logistic regression and random undersampled (converted 10000 rows to 4209) only scaled the non-binary features \n",
    "- pursue decision tree classifier\n",
    "- am i on track in what i have so far?\n",
    "- how to iteratively push to github from terminal\n",
    "- additional tips on completing remainder of project - probing questions to think of?\n",
    "\n",
    "Mark Notes\n",
    "- Try doing one without RUS, and then one with (this is a baseline)\n",
    "- Our accuracy would be overly confident wihtout RUS\n",
    "- Use F1 score and accuracy as north star, then precision and recall\n",
    "- If there's no diff in F1 score, then use the model with RUS and then focus on accuracy. If not then stick with model with best F1 score\n",
    "- Then can do decision tree with best model\n",
    "- compare feature importance and coefficients between better baseline model and decision tree evaluation\n",
    "- then it will give me best recs. if there are similarities between the two then it will tell me what features are the best to use\n",
    "\n",
    "- correct on only scaling non binary features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
